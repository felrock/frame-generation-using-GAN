{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last frame generation using CGAN, based on pix2pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I make a conditional GAN with the first and last frame from clips from the flying shapes data set.  \n",
    "Constant variables(below the imports) are changed to change the behavior of the GAN.  \n",
    "The data set is a derivation of the flying shapes data set, adding colour and one more shape.  \n",
    "\n",
    "\n",
    "Refs:  \n",
    "Flying shapes - https://arxiv.org/abs/1807.00703  \n",
    "pix2pix - https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import functools\n",
    "\n",
    "# for image display\n",
    "import IPython.display as display\n",
    "import PIL.Image\n",
    "\n",
    "# ML, vector util\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant variables\n",
    "training_data_dir = \"/FlyingObjectDataset_10K/training/image/\"\n",
    "validation_data_dir = \"/FlyingObjectDataset_10K/validation/image/\"\n",
    "testing_data_dir = \"/FlyingObjectDataset_10K/testing/image/\"   \n",
    "GPU = 0 # GPU ID\n",
    "DROPOUT_PROB = 0.5\n",
    "IMAGE_WIDTH = 128\n",
    "IMAGE_HEIGHT = 128 \n",
    "IMAGE_CHANNEL = 3 \n",
    "EPOCHS = 12\n",
    "BATCH_SIZE = 5           \n",
    "SEQUENCE_LENGTH = 10 \n",
    "LEARNING_RATE_GEN = 1e-4\n",
    "LEARNING_RATE_DISC = 1e-4\n",
    "DATA_AUGMENTATION = True\n",
    "DATASET_LENGTH = 300\n",
    "VAL_DATASET_LENGTH = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GPU configuration\n",
    "if GPU >=0:\n",
    "    print(\"creating network model using gpu \" + str(GPU))\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU)\n",
    "elif GPU >=-1:\n",
    "    print(\"creating network model using cpu \")  \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(image_dir):\n",
    "    \"\"\"\n",
    "        Load image from dir, apply resizing and normalization\n",
    "    \"\"\"\n",
    "\n",
    "    temp_image = tf.io.read_file(image_dir)\n",
    "    temp_image = tf.image.decode_png(temp_image)\n",
    "    \n",
    "    # change to specified size\n",
    "    temp_image = tf.image.resize(temp_image, [IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    temp_image = tf.cast(temp_image, tf.float32)\n",
    "\n",
    "    return temp_image\n",
    "\n",
    "def normalize(temp_image):\n",
    "    \n",
    "    # change pixel values to float numbers between -1 and 1\n",
    "    temp_image = (temp_image / 127.5) - 1\n",
    "    return temp_image\n",
    "\n",
    "def showTensorImage(tensor_img):\n",
    "    \"\"\"\n",
    "        Displays an image given as tensor object\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove norm and re-cast\n",
    "    tensor_img = tf.squeeze(tensor_img, 0)\n",
    "    disp_image = tensorToNumpy(tensor_img)\n",
    "    display.display(PIL.Image.fromarray(disp_image))\n",
    "    \n",
    "def tensorToNumpy(tensor):\n",
    "    \n",
    "    disp_image = (tensor + 1) *127.5\n",
    "    disp_image = tf.cast(disp_image, tf.uint8)\n",
    "    return np.array(disp_image)\n",
    "    \n",
    "def randomJitter(first, last):\n",
    "    \"\"\"Random jittering.\n",
    "        Resizes to 286 x 286 and then randomly crops to IMG_HEIGHT x IMG_WIDTH.\n",
    "        Args:\n",
    "        input_image: Input Image\n",
    "        real_image: Real Image\n",
    "        Returns:\n",
    "        Input Image, real image\n",
    "    \"\"\"\n",
    "    # resizing to 148 x 148 x 3\n",
    "    input_image1 = tf.image.resize(first, [148, 148],\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    input_image2 = tf.image.resize(last, [148, 148],\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # randomly cropping to 128 x 128 x 3\n",
    "    stacked_image = tf.stack([input_image1, input_image2], axis=0)\n",
    "\n",
    "    cropped_image = tf.image.random_crop(\n",
    "            stacked_image, size=[2, IMAGE_HEIGHT, IMAGE_WIDTH, 3])\n",
    "    \n",
    "    input_image1, input_image2 = cropped_image[0], cropped_image[1]\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        # random mirroring\n",
    "        input_image1 = tf.image.flip_left_right(input_image1)\n",
    "        input_image2 = tf.image.flip_left_right(input_image2)\n",
    "\n",
    "    return input_image1, input_image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_eren_generator(data_dir):\n",
    "\n",
    "    # data set lists\n",
    "    first_frame_dirs, last_frame_dirs = [], []\n",
    "\n",
    "    # globs for png images\n",
    "    training_dirs = glob.glob(data_dir + '/*.png')\n",
    "\n",
    "    # sort files, this way all the frames are in order\n",
    "    training_dirs.sort()\n",
    "    \n",
    "    # first and last frame dirs, set first for bootstrap\n",
    "    temp_first_dir, temp_last_dir = training_dirs[0], ''\n",
    "\n",
    "    # iterate over image dirs and load them using tf.io\n",
    "    first_frame_count = 0\n",
    "    for temp_dir in training_dirs[1:]:\n",
    "\n",
    "        # parse dir\n",
    "        file_name   = temp_dir.split('/')[-1]\n",
    "        frame_name  = file_name.split('_')[-1]\n",
    "        frame_count = int(frame_name.replace('.png', ''))\n",
    "\n",
    "        if frame_count == 1:\n",
    "            \n",
    "            # save dirs\n",
    "            last_frame_dirs += [first_frame_dirs[-1]]*first_frame_count\n",
    "            first_frame_dirs.append(temp_first_dir)\n",
    "\n",
    "            # remove last image\n",
    "            first_frame_dirs = first_frame_dirs[:-1]\n",
    "            first_frame_count = 0\n",
    "        else:\n",
    "            first_frame_count += 1\n",
    "            first_frame_dirs.append(temp_dir)\n",
    "      \n",
    "    pair_dirs = list(zip(first_frame_dirs, last_frame_dirs))\n",
    "\n",
    "    while True:\n",
    "        random.shuffle(pair_dirs)\n",
    "        \n",
    "        f1_ar = []\n",
    "        f2_ar = []\n",
    "        # iterate over image dirs and load them using tf.io\n",
    "        for first_frame, last_frame in pair_dirs:\n",
    "\n",
    "            f1, f2 = loadImage(first_frame), loadImage(last_frame)\n",
    "            if DATA_AUGMENTATION:\n",
    "                f1, f2 = randomJitter(f1, f2)\n",
    "            f1, f2 = normalize(f1), normalize(f2)\n",
    "            \n",
    "            yield f1, f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_task_generator(data_dir):\n",
    "\n",
    "    # data set lists\n",
    "    first_frame_dirs, last_frame_dirs = [], []\n",
    "\n",
    "    # globs for png images\n",
    "    training_dirs = glob.glob(data_dir + '/*.png')\n",
    "\n",
    "    # sort files, this way all the frames are in order\n",
    "    training_dirs.sort()\n",
    "    \n",
    "    # first and last frame dirs, set first for bootstrap\n",
    "    temp_first_dir, temp_last_dir = training_dirs[0], ''\n",
    "\n",
    "    # iterate over image dirs and load them using tf.io\n",
    "    for temp_dir in training_dirs[1:]:\n",
    "\n",
    "        # parse dir\n",
    "        file_name   = temp_dir.split('/')[-1]\n",
    "        frame_name  = file_name.split('_')[-1]\n",
    "        frame_count = int(frame_name.replace('.png', ''))\n",
    "\n",
    "        if frame_count == 1:\n",
    "            # save dirs\n",
    "            first_frame_dirs.append(temp_first_dir)\n",
    "            last_frame_dirs.append(temp_last_dir)\n",
    "            \n",
    "            # set next first frame\n",
    "            temp_first_dir = temp_dir\n",
    "        else:\n",
    "            temp_last_dir = temp_dir\n",
    "            \n",
    "    pair_dirs = list(zip(first_frame_dirs, last_frame_dirs))\n",
    "    \n",
    "    while True:\n",
    "        random.shuffle(pair_dirs)\n",
    "        \n",
    "        f1_ar = []\n",
    "        f2_ar = []\n",
    "        # iterate over image dirs and load them using tf.io\n",
    "        for first_frame, last_frame in pair_dirs:\n",
    "\n",
    "            f1, f2 = loadImage(first_frame), loadImage(last_frame)\n",
    "            if DATA_AUGMENTATION:\n",
    "                f1, f2 = randomJitter(f1, f2)\n",
    "            f1, f2 = normalize(f1), normalize(f2)\n",
    "            \n",
    "            yield f1, f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNormalization(tf.keras.layers.Layer):\n",
    "    \"\"\"Instance Normalization Layer (https://arxiv.org/abs/1607.08022).\"\"\"\n",
    "\n",
    "    def __init__(self, epsilon=1e-5):\n",
    "        super(InstanceNormalization, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.scale = self.add_weight(\n",
    "            name='scale',\n",
    "            shape=input_shape[-1:],\n",
    "            initializer=tf.random_normal_initializer(1., 0.02),\n",
    "            trainable=True)\n",
    "\n",
    "        self.offset = self.add_weight(\n",
    "            name='offset',\n",
    "            shape=input_shape[-1:],\n",
    "            initializer='zeros',\n",
    "            trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "        inv = tf.math.rsqrt(variance + self.epsilon)\n",
    "        normalized = (x - mean) * inv\n",
    "        return self.scale * normalized + self.offset\n",
    "\n",
    "\n",
    "def downsample(filters, size, norm_type='batchnorm', apply_norm=True):\n",
    "    \"\"\"Downsamples an input.\n",
    "        Conv2D => Batchnorm => LeakyRelu\n",
    "        Args:\n",
    "        filters: number of filters\n",
    "        size: filter size\n",
    "        norm_type: Normalization type; either 'batchnorm' or 'instancenorm'.\n",
    "        apply_norm: If True, adds the batchnorm layer\n",
    "        Returns:\n",
    "        Downsample Sequential Model\n",
    "    \"\"\"\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "                 tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                 kernel_initializer=initializer))\n",
    "\n",
    "    if apply_norm:\n",
    "        if norm_type.lower() == 'batchnorm':\n",
    "            result.add(tf.keras.layers.BatchNormalization())\n",
    "        elif norm_type.lower() == 'instancenorm':\n",
    "            result.add(InstanceNormalization())\n",
    "            \n",
    "    result.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    return result\n",
    "\n",
    "def upsample(filters, size, norm_type='batchnorm', apply_dropout=False):\n",
    "    \"\"\"Upsamples an input.\n",
    "        Conv2DTranspose => Batchnorm => Dropout => Relu\n",
    "        Args:\n",
    "        filters: number of filters\n",
    "        size: filter size\n",
    "        norm_type: Normalization type; either 'batchnorm' or 'instancenorm'.\n",
    "        apply_dropout: If True, adds the dropout layer\n",
    "        Returns:\n",
    "        Upsample Sequential Model\n",
    "    \"\"\"\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                  padding='same',\n",
    "                  kernel_initializer=initializer))\n",
    "    \n",
    "    if norm_type.lower() == 'batchnorm':\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "    elif norm_type.lower() == 'instancenorm':\n",
    "        result.add(InstanceNormalization())\n",
    "        \n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "        \n",
    "    result.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_generator(output_channels, input_shape, norm_type='batchnorm'):\n",
    "    \"\"\"Modified u-net generator model (https://arxiv.org/abs/1611.07004).\n",
    "        Args:\n",
    "        output_channels: Output channels\n",
    "        norm_type: Type of normalization. Either 'batchnorm' or 'instancenorm'.\n",
    "        Returns:\n",
    "        Generator model\n",
    "    \"\"\"\n",
    "\n",
    "    down_stack = [\n",
    "        downsample(128, 4, norm_type, apply_norm=False),  # (bs, 64, 64, 128)\n",
    "        downsample(256, 4, norm_type),  # (bs, 32, 32, 256)\n",
    "        downsample(256, 4, norm_type),  # (bs, 16, 16, 256)\n",
    "        downsample(512, 4, norm_type),  # (bs, 8, 8, 512)\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(512, 4, norm_type, apply_dropout=True),  # (bs, 16, 16, 512)\n",
    "        upsample(256, 4, norm_type, apply_dropout=True),  # (bs, 32, 32, 256)\n",
    "        upsample(256, 4, norm_type),  # (bs, 64, 64, 256)\n",
    "        upsample(128, 4, norm_type),  # (bs, 128, 128, 128)\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(\n",
    "            output_channels, 4, strides=2,\n",
    "            padding='same', kernel_initializer=initializer,\n",
    "            activation='tanh')  # (bs, 128, 128, 3)\n",
    "\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_shape):\n",
    "    \"\"\"PatchGan discriminator model (https://arxiv.org/abs/1611.07004).\n",
    "        Args:\n",
    "        input_shape: shape of the input image.\n",
    "        Returns:\n",
    "        Discriminator model\n",
    "    \"\"\"\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=input_shape, name='input_image')\n",
    "\n",
    "    # first down-stack\n",
    "    down1 = tf.keras.layers.Conv2D(128, (4, 4), strides=2, padding='same')(inp)\n",
    "    down1 = tf.keras.layers.Activation('relu')(down1)\n",
    "    # second down-stack    \n",
    "    down2 = tf.keras.layers.Conv2D(256, (4, 4), strides=2, padding='same')(down1)\n",
    "    down2 = tf.keras.layers.Activation('relu')(down2)\n",
    "    # third down-stack  \n",
    "    down3 = tf.keras.layers.Conv2D(512, (4, 4), strides=2, padding='same')(down2)\n",
    "    down3 = tf.keras.layers.Activation('relu')(down3)\n",
    "    \n",
    "    output = tf.keras.layers.Conv2D(1, (4, 4), strides=2, padding='same', activation='sigmoid')(down3)\n",
    "\n",
    "    return tf.keras.Model(inputs=inp, outputs=output)\n",
    "\n",
    "def c_discriminator(input_shape):\n",
    "    \"\"\"PatchGan discriminator model (https://arxiv.org/abs/1611.07004).\n",
    "        with conditioned input\n",
    "        Args:\n",
    "        input_shape: shape of the input image.\n",
    "        Returns:\n",
    "        Discriminator model\n",
    "    \"\"\"\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=input_shape, name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=input_shape, name='target_image')\n",
    "    \n",
    "    inp_con = tf.keras.layers.Concatenate(axis=-1)([inp, tar])  # (bs, 256, 256, channels*2)\n",
    "\n",
    "    # first down-stack\n",
    "    down1 = tf.keras.layers.Conv2D(128, (4, 4), strides=2, padding='same')(inp_con)\n",
    "    down1 = tf.keras.layers.Activation('relu')(down1)\n",
    "    # second down-stack    \n",
    "    down2 = tf.keras.layers.Conv2D(256, (4, 4), strides=2, padding='same')(down1)\n",
    "    down2 = tf.keras.layers.Activation('relu')(down2)\n",
    "    # third down-stack  \n",
    "    down3 = tf.keras.layers.Conv2D(512, (4, 4), strides=2, padding='same')(down2)\n",
    "    down3 = tf.keras.layers.Activation('relu')(down3)\n",
    "    \n",
    "    output = tf.keras.layers.Conv2D(1, (4, 4), strides=2, padding='same', activation='sigmoid')(down3)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN class implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P2pGAN(object):\n",
    "    \"\"\"\n",
    "        Class implementation of a pix2pix GAN with specified optimizers, loss-functions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, epochs, input_shape):\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.lambda_value = 100\n",
    "        self.loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.generator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE_GEN)\n",
    "        self.discriminator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE_DISC)\n",
    "        self.generator = unet_generator(3, input_shape)\n",
    "        self.discriminator = c_discriminator(input_shape)\n",
    "        \n",
    "        self.checkpoint = tf.train.Checkpoint(\n",
    "            generator_optimizer=self.generator_optimizer,\n",
    "            discriminator_optimizer=self.discriminator_optimizer)\n",
    "    \n",
    "    def train(self, train_gen, val_gen, checkpoint_pr):\n",
    "        \"\"\"Train the GAN for x number of epochs.\n",
    "        Args:\n",
    "        dataset: train dataset.\n",
    "        checkpoint_pr: prefix in which the checkpoints are stored.\n",
    "        Returns:\n",
    "        Training step losses\n",
    "        \"\"\"\n",
    "        \n",
    "        loss_list = []\n",
    "\n",
    "        for epoch in range(1, self.epochs+1):\n",
    "            \n",
    "            # total loss variables\n",
    "            t_disc_real_loss = 0\n",
    "            t_disc_fake_loss = 0\n",
    "            t_gen_bce_loss   = 0\n",
    "            t_gen_mse_loss   = 0\n",
    "            gen_update_index = 0\n",
    "            \n",
    "            for _ in range(DATASET_LENGTH):\n",
    "                \n",
    "                # create batch\n",
    "                input_images  = []\n",
    "                target_images = []\n",
    "                for _ in range(BATCH_SIZE):\n",
    "                    a, b = next(train_gen)\n",
    "                    input_images.append(a)\n",
    "                    target_images.append(b)\n",
    "                input_images  = tf.convert_to_tensor(input_images)\n",
    "                target_images = tf.convert_to_tensor(target_images)\n",
    "                \n",
    "                # only update generator every third discriminator update\n",
    "                disc_loss, gen_loss = self.train_step(input_images,\n",
    "                                                          target_images,\n",
    "                                                          True,\n",
    "                                                          True)                   \n",
    "                # update index\n",
    "                gen_update_index += 1\n",
    "                \n",
    "                # update totals\n",
    "                t_disc_real_loss += disc_loss[0]\n",
    "                t_disc_fake_loss += disc_loss[1]\n",
    "                t_gen_bce_loss   += gen_loss[0]\n",
    "                t_gen_mse_loss   += gen_loss[1]\n",
    "                    \n",
    "            # update loss totals, avg\n",
    "            tgl = (t_gen_bce_loss/DATASET_LENGTH, t_gen_mse_loss/DATASET_LENGTH)\n",
    "            tdl = (t_disc_real_loss/DATASET_LENGTH, t_disc_fake_loss/DATASET_LENGTH)\n",
    "            loss_list.append((tgl, tdl))\n",
    "            \n",
    "            \n",
    "                \n",
    "            # print epoch status\n",
    "            val_str = self.validate(val_gen)\n",
    "            template = 'Epoch {}, Generator loss {}, Discriminator Loss {}'\n",
    "            print(template.format(epoch, tgl[0]+tgl[1], tdl[0]+tdl[1]) + val_str)\n",
    "            \n",
    "            # saving (checkpoint) the model every 20 epochs\n",
    "            if (epoch + 1) % 20 == 0:\n",
    "                self.checkpoint.save(file_prefix=checkpoint_pr)\n",
    "\n",
    "        return loss_list\n",
    "    \n",
    "    def validate(self, data_gen):\n",
    "        \"\"\"One validation step over the generator and discriminator model.\n",
    "           This function does not update any weights.\n",
    "        Args:\n",
    "          data_gen: data generator, validation set.\n",
    "        Returns:\n",
    "          generator loss, discriminator loss.\n",
    "        \"\"\"\n",
    "        \n",
    "        t_disc_loss, t_gen_loss = 0, 0\n",
    "        for _ in range(VAL_DATASET_LENGTH):\n",
    "            # create batch\n",
    "            input_images  = []\n",
    "            target_images = []\n",
    "            for _ in range(BATCH_SIZE):\n",
    "                a, b = next(data_gen)\n",
    "                input_images.append(a)\n",
    "                target_images.append(b)\n",
    "            input_images  = tf.convert_to_tensor(input_images)\n",
    "            target_images = tf.convert_to_tensor(target_images)\n",
    "\n",
    "            # run w/o updating gradients\n",
    "            disc_loss, gen_loss = self.train_step(input_images,\n",
    "                                                  target_images,\n",
    "                                                  False,\n",
    "                                                  False)\n",
    "            t_disc_loss += disc_loss[0] + disc_loss[1]\n",
    "            t_gen_loss  += gen_loss[0] + gen_loss[1]\n",
    "        # return validation string\n",
    "        template = '\\nValidation, Generator loss {}, Discriminator Loss {}\\n'\n",
    "        return template.format(t_gen_loss/VAL_DATASET_LENGTH, t_disc_loss/VAL_DATASET_LENGTH)\n",
    "        \n",
    "    \n",
    "    def train_step(self, input_image, target_image, update_gen=True, update_disc=True):\n",
    "        \"\"\"One train step over the generator and discriminator model.\n",
    "        Args:\n",
    "          input_image: Input Image, batch\n",
    "          target_image: Target image, batch\n",
    "          update_gen: Boolean to update.\n",
    "          update_disc: Boolean to update.\n",
    "        Returns:\n",
    "          generator loss, discriminator loss.\n",
    "        \"\"\"\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "\n",
    "            # Generate a fake last frame   \n",
    "            gen_output = self.generator(input_image)\n",
    "\n",
    "            # Discriminator infer fake and real frame\n",
    "            disc_real_output = self.discriminator([input_image, target_image])\n",
    "            disc_gen_output = self.discriminator([input_image, gen_output])\n",
    "\n",
    "            # Get loss\n",
    "            d_real_loss, d_gen_loss = self.discriminator_loss_bce(\n",
    "                disc_real_output, disc_gen_output)\n",
    "            gan_bce_loss, gan_mse_loss = self.generator_loss(\n",
    "                disc_gen_output, gen_output, target_image)\n",
    "            \n",
    "            if update_gen:\n",
    "                # Get gradients from gradient tape\n",
    "                generator_gradients = gen_tape.gradient(\n",
    "                    gan_bce_loss + gan_mse_loss, \n",
    "                    self.generator.trainable_variables)\n",
    "                # Apply new gradients to discriminator and generator\n",
    "                self.generator_optimizer.apply_gradients(zip(\n",
    "                    generator_gradients, self.generator.trainable_variables))\n",
    "                \n",
    "            if update_disc:\n",
    "                # Get gradients from gradient tape\n",
    "                discriminator_gradients = disc_tape.gradient(\n",
    "                    d_real_loss + d_gen_loss, self.discriminator.trainable_variables)\n",
    "                # Apply new gradients to discriminator and generator\n",
    "                self.discriminator_optimizer.apply_gradients(zip(\n",
    "                    discriminator_gradients, self.discriminator.trainable_variables))\n",
    "            \n",
    "        return (d_real_loss, d_gen_loss), (gan_bce_loss, gan_mse_loss)\n",
    "    \n",
    "    def discriminator_loss(self, disc_real_output, disc_gen_output):\n",
    "        \"\"\"Calculates discriminator loss, on both fake and real samples\n",
    "        Args:\n",
    "          disc_real_output: Discriminator output, real image\n",
    "          disc_gen_output: Discriminator output, fake image\n",
    "        Returns:\n",
    "          discriminator loss.\n",
    "        \"\"\"\n",
    "        \n",
    "        # calc loss on real/fake inputs to discriminator\n",
    "        real_loss      = -tf.reduce_mean(disc_real_output)\n",
    "        generated_loss = tf.reduce_mean(disc_gen_output)\n",
    "\n",
    "        return real_loss, generated_loss\n",
    "\n",
    "    def generator_loss(self, disc_gen_output, gen_output, target):\n",
    "        \"\"\"Calculates generator loss, with the chosen loss function and\n",
    "           MeanSquareError on faked image and target image.\n",
    "        Args:\n",
    "          disc_gen_output: Discriminator output, real image\n",
    "          gen_output: faked image\n",
    "          target: Target\n",
    "        Returns:\n",
    "          Generator loss\n",
    "        \"\"\"        \n",
    "        # calc loss from discriminator\n",
    "        gan_loss = self.loss_object(tf.ones_like(\n",
    "            disc_gen_output), disc_gen_output)\n",
    "\n",
    "        # mean square error\n",
    "        l1_loss = tf.reduce_mean(tf.pow(target - gen_output, 2))\n",
    "\n",
    "        return gan_loss, l1_loss*self.lambda_value\n",
    "    \n",
    "    def discriminator_loss_bce(self, disc_real_output, disc_gen_output):\n",
    "        \"\"\"Calculates discriminator loss, with chosen loss function(BinaryCrossentropy)\n",
    "        Args:\n",
    "          disc_gen_output: Discriminator output, real image\n",
    "          gen_output: faked image\n",
    "          target: Target\n",
    "        Returns:\n",
    "          Generator loss\n",
    "        \"\"\" \n",
    "        # calc loss from discriminator, real images\n",
    "        real_loss = self.loss_object(\n",
    "            tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "        # calc loss from discriminator, fakes images\n",
    "        generated_loss = self.loss_object(tf.zeros_like(\n",
    "            disc_gen_output), disc_gen_output)\n",
    "        \n",
    "        return real_loss, generated_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following blocks are for testing\n",
    "current_log_folder = './log/ckpt-{}/'.format(str(datetime.datetime.now()))\n",
    "os.mkdir(current_log_folder)\n",
    "image_count = 0\n",
    "p2p = P2pGAN(EPOCHS, (128, 128, 3))\n",
    "t1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "gan_losses = p2p.train(data_task_generator(training_data_dir), data_task_generator(validation_data_dir), current_log_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create testing data set generator, swap training/test generator\n",
    "dg = data_eren_generator(testing_data_dir)\n",
    "generator = p2p.generator\n",
    "# generator = tf.keras.models.load_model('./log/keras-gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next testing sample\n",
    "f1, f2 = next(dg)\n",
    "# for batch\n",
    "f1, f2 = tf.expand_dims(f1, 0), tf.expand_dims(f2, 0)\n",
    "img = generator(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round-up predicted colors\n",
    "img_np = img.numpy()\n",
    "with np.nditer(img_np, op_flags=['readwrite']) as it:\n",
    "    for x in it:\n",
    "        if x > 0.5:\n",
    "            x[...] = 1.0\n",
    "        else:\n",
    "            x[...] = 0.0\n",
    "img_tens = tf.convert_to_tensor(img_np, tf.float32)\n",
    "\n",
    "# display input/target/pred and rounded up version of pred(img_tens)\n",
    "img_both = np.hstack([tensorToNumpy(tf.squeeze(f1, 0)), tensorToNumpy(tf.squeeze(f2, 0)), tensorToNumpy(tf.squeeze(img, 0))])\n",
    "result = PIL.Image.fromarray(img_both)\n",
    "image_count += 1\n",
    "result.save(current_log_folder +'out{}.bmp'.format(image_count))\n",
    "display.display(PIL.Image.fromarray(img_both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# epoch list\n",
    "x = [ t for t in range(1, len(gan_losses)+1)]\n",
    "# loss lists\n",
    "y1 = [float(t[0][0]) for t in gan_losses]\n",
    "y2 = [float(t[0][1]) for t in gan_losses]\n",
    "y3 = [float(t[1][0]) for t in gan_losses]\n",
    "y4 = [float(t[1][1]) for t in gan_losses]\n",
    "fig, axs = plt.subplots(2,2, figsize=(10,4))\n",
    "# disc_real\n",
    "axs[0, 0].plot(x, y1)\n",
    "axs[0, 0].set_xlabel('Epochs')\n",
    "axs[0, 0].set_ylabel('G bce Loss')\n",
    "# disc fake\n",
    "axs[0, 1].plot(x, y2)\n",
    "axs[0, 1].set_xlabel('Epochs')\n",
    "axs[0, 1].set_ylabel('G mse Loss')\n",
    "# gen bce\n",
    "axs[1, 0].plot(x, y3)\n",
    "axs[1, 0].set_xlabel('Epochs')\n",
    "axs[1, 0].set_ylabel('D real Loss')\n",
    "# gen mse\n",
    "axs[1, 1].plot(x, y4)\n",
    "axs[1, 1].set_xlabel('Epochs')\n",
    "axs[1, 1].set_ylabel('D fake Loss')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('colapse_to_white.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#tf.keras.models.save_model(p2p.discriminator, './log/keras-disc/')\n",
    "#tf.keras.models.save_model(p2p.generator, './log/keras-gen/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
